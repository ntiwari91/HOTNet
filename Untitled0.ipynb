{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"qmAkrTBpphZU"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":47,"status":"ok","timestamp":1702044959384,"user":{"displayName":"Jaya Chauhan","userId":"14094591080657712937"},"user_tz":-330},"id":"N0JcTmrGp37k","outputId":"ea77a20e-c2ec-4656-9937-70eb3427c85b"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/US3RN-main\n"]}],"source":["cd /content/drive/MyDrive/US3RN-main"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39,"status":"ok","timestamp":1702044959386,"user":{"displayName":"Jaya Chauhan","userId":"14094591080657712937"},"user_tz":-330},"id":"hffUlAYXp5lx","outputId":"2de8ebaa-ba79-4655-cce0-3a5898bdeee9"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34mdata\u001b[0m/    dataset.py  model.py    \u001b[01;34mNONLOCAL\u001b[0m/  \u001b[01;34m__pycache__\u001b[0m/  \u001b[01;34mresult\u001b[0m/     \u001b[01;34mTrainedNet\u001b[0m/\n","data.py  main.py     modules.py  psnr.py    README.md     \u001b[01;34mtb_logger\u001b[0m/  Untitled0.ipynb\n"]}],"source":["ls"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xfiumcN880uK","executionInfo":{"status":"ok","timestamp":1702047629534,"user_tz":-330,"elapsed":2334096,"user":{"displayName":"Jaya Chauhan","userId":"14094591080657712937"}},"outputId":"00611c75-fd1c-4be1-e134-1b88f81840ae"},"outputs":[{"output_type":"stream","name":"stdout","text":["2023-12-08 14:21:38.711706: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-12-08 14:21:38.711780: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-12-08 14:21:38.711820: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2023-12-08 14:21:39.787757: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Namespace(upscale_factor=4, batchSize=8, patch_size=64, testBatchSize=1, ChDim=31, alpha=0.2, nEpochs=0, lr=0.0001, threads=2, seed=123, save_folder='TrainedNet/', outputpath='result/', mode='train')\n","===> Loading datasets\n","===> Building model\n","# network parameters: 295164\n","---  There exsits folder TrainedNet/ !  ---\n","---  There exsits folder result/ !  ---\n","===> Epoch[1](100/2500): Loss: 0.4754\n","===> Epoch[1](200/2500): Loss: 0.2747\n","===> Epoch[1](300/2500): Loss: 0.2999\n","===> Epoch[1](400/2500): Loss: 0.3442\n","===> Epoch[1](500/2500): Loss: 0.2478\n","===> Epoch[1](600/2500): Loss: 0.2227\n","===> Epoch[1](700/2500): Loss: 0.2204\n","===> Epoch[1](800/2500): Loss: 0.2020\n","===> Epoch[1](900/2500): Loss: 0.1836\n","===> Epoch[1](1000/2500): Loss: 0.3250\n","===> Epoch[1](1100/2500): Loss: 0.2847\n","===> Epoch[1](1200/2500): Loss: 0.2274\n","===> Epoch[1](1300/2500): Loss: 0.1830\n","===> Epoch[1](1400/2500): Loss: 0.3220\n","===> Epoch[1](1500/2500): Loss: 0.2621\n","===> Epoch[1](1600/2500): Loss: 0.1902\n","===> Epoch[1](1700/2500): Loss: 0.1971\n","===> Epoch[1](1800/2500): Loss: 0.2222\n","===> Epoch[1](1900/2500): Loss: 0.2052\n","===> Epoch[1](2000/2500): Loss: 0.2305\n","===> Epoch[1](2100/2500): Loss: 0.1947\n","===> Epoch[1](2200/2500): Loss: 0.2356\n","===> Epoch[1](2300/2500): Loss: 0.2615\n","===> Epoch[1](2400/2500): Loss: 0.1586\n","===> Epoch[1](2500/2500): Loss: 0.1991\n","===> Epoch 1 Complete: Avg. Loss: 0.3968\n","===> Epoch[2](100/2500): Loss: 0.1615\n","===> Epoch[2](200/2500): Loss: 0.2614\n","===> Epoch[2](300/2500): Loss: 0.1331\n","===> Epoch[2](400/2500): Loss: 0.1825\n","===> Epoch[2](500/2500): Loss: 0.1985\n","===> Epoch[2](600/2500): Loss: 0.1188\n","===> Epoch[2](700/2500): Loss: 0.2014\n","===> Epoch[2](800/2500): Loss: 0.2021\n","===> Epoch[2](900/2500): Loss: 0.2367\n","===> Epoch[2](1000/2500): Loss: 0.2119\n","===> Epoch[2](1100/2500): Loss: 0.2242\n","===> Epoch[2](1200/2500): Loss: 0.1815\n","===> Epoch[2](1300/2500): Loss: 0.2258\n","===> Epoch[2](1400/2500): Loss: 0.2481\n","===> Epoch[2](1500/2500): Loss: 0.1719\n","===> Epoch[2](1600/2500): Loss: 0.1521\n","===> Epoch[2](1700/2500): Loss: 0.1433\n","===> Epoch[2](1800/2500): Loss: 0.2174\n","===> Epoch[2](1900/2500): Loss: 0.1434\n","===> Epoch[2](2000/2500): Loss: 0.1167\n","===> Epoch[2](2100/2500): Loss: 0.1960\n","===> Epoch[2](2200/2500): Loss: 0.1728\n","===> Epoch[2](2300/2500): Loss: 0.2241\n","===> Epoch[2](2400/2500): Loss: 0.1634\n","===> Epoch[2](2500/2500): Loss: 0.1430\n","===> Epoch 2 Complete: Avg. Loss: 0.1926\n","===> Epoch[3](100/2500): Loss: 0.1699\n","===> Epoch[3](200/2500): Loss: 0.2328\n","===> Epoch[3](300/2500): Loss: 0.1978\n","===> Epoch[3](400/2500): Loss: 0.2750\n","===> Epoch[3](500/2500): Loss: 0.2026\n","===> Epoch[3](600/2500): Loss: 0.1897\n","===> Epoch[3](700/2500): Loss: 0.1151\n","===> Epoch[3](800/2500): Loss: 0.1707\n","===> Epoch[3](900/2500): Loss: 0.1517\n","===> Epoch[3](1000/2500): Loss: 0.2443\n","===> Epoch[3](1100/2500): Loss: 0.3001\n","===> Epoch[3](1200/2500): Loss: 0.1355\n","===> Epoch[3](1300/2500): Loss: 0.2020\n","===> Epoch[3](1400/2500): Loss: 0.1087\n","===> Epoch[3](1500/2500): Loss: 0.2005\n","===> Epoch[3](1600/2500): Loss: 0.1274\n","===> Epoch[3](1700/2500): Loss: 0.1764\n","===> Epoch[3](1800/2500): Loss: 0.1287\n","===> Epoch[3](1900/2500): Loss: 0.1897\n","===> Epoch[3](2000/2500): Loss: 0.1441\n","===> Epoch[3](2100/2500): Loss: 0.1432\n","===> Epoch[3](2200/2500): Loss: 0.2016\n","===> Epoch[3](2300/2500): Loss: 0.2581\n","===> Epoch[3](2400/2500): Loss: 0.1077\n","===> Epoch[3](2500/2500): Loss: 0.2356\n","===> Epoch 3 Complete: Avg. Loss: 0.1834\n","===> Epoch[4](100/2500): Loss: 0.1640\n","===> Epoch[4](200/2500): Loss: 0.2150\n","===> Epoch[4](300/2500): Loss: 0.1817\n","===> Epoch[4](400/2500): Loss: 0.1083\n","===> Epoch[4](500/2500): Loss: 0.2492\n","===> Epoch[4](600/2500): Loss: 0.0795\n","===> Epoch[4](700/2500): Loss: 0.1780\n","===> Epoch[4](800/2500): Loss: 0.2409\n","===> Epoch[4](900/2500): Loss: 0.1994\n","===> Epoch[4](1000/2500): Loss: 0.2435\n","===> Epoch[4](1100/2500): Loss: 0.1761\n","===> Epoch[4](1200/2500): Loss: 0.1334\n","===> Epoch[4](1300/2500): Loss: 0.1427\n","===> Epoch[4](1400/2500): Loss: 0.1783\n","===> Epoch[4](1500/2500): Loss: 0.1873\n","===> Epoch[4](1600/2500): Loss: 0.1416\n","===> Epoch[4](1700/2500): Loss: 0.1186\n","===> Epoch[4](1800/2500): Loss: 0.2334\n","===> Epoch[4](1900/2500): Loss: 0.1403\n","===> Epoch[4](2000/2500): Loss: 0.1564\n","===> Epoch[4](2100/2500): Loss: 0.2481\n","===> Epoch[4](2200/2500): Loss: 0.1266\n","===> Epoch[4](2300/2500): Loss: 0.2131\n","===> Epoch[4](2400/2500): Loss: 0.2070\n","===> Epoch[4](2500/2500): Loss: 0.1442\n","===> Epoch 4 Complete: Avg. Loss: 0.1801\n","===> Epoch[5](100/2500): Loss: 0.2308\n","===> Epoch[5](200/2500): Loss: 0.2910\n","===> Epoch[5](300/2500): Loss: 0.1009\n","===> Epoch[5](400/2500): Loss: 0.2366\n","===> Epoch[5](500/2500): Loss: 0.2171\n","===> Epoch[5](600/2500): Loss: 0.0889\n","===> Epoch[5](700/2500): Loss: 0.2081\n","===> Epoch[5](800/2500): Loss: 0.2196\n","===> Epoch[5](900/2500): Loss: 0.2049\n","===> Epoch[5](1000/2500): Loss: 0.2160\n","===> Epoch[5](1100/2500): Loss: 0.2790\n","===> Epoch[5](1200/2500): Loss: 0.1797\n","===> Epoch[5](1300/2500): Loss: 0.1644\n","===> Epoch[5](1400/2500): Loss: 0.0782\n","===> Epoch[5](1500/2500): Loss: 0.1247\n","===> Epoch[5](1600/2500): Loss: 0.2064\n","===> Epoch[5](1700/2500): Loss: 0.1821\n","===> Epoch[5](1800/2500): Loss: 0.1693\n","===> Epoch[5](1900/2500): Loss: 0.1461\n","===> Epoch[5](2000/2500): Loss: 0.1929\n","===> Epoch[5](2100/2500): Loss: 0.2467\n","===> Epoch[5](2200/2500): Loss: 0.1459\n","===> Epoch[5](2300/2500): Loss: 0.2600\n","===> Epoch[5](2400/2500): Loss: 0.1608\n","===> Epoch[5](2500/2500): Loss: 0.1626\n","===> Epoch 5 Complete: Avg. Loss: 0.1754\n","Checkpoint saved to TrainedNet/_epoch_5.pth\n","===> Epoch[6](100/2500): Loss: 0.1211\n","===> Epoch[6](200/2500): Loss: 0.1314\n","===> Epoch[6](300/2500): Loss: 0.2269\n","===> Epoch[6](400/2500): Loss: 0.1950\n","===> Epoch[6](500/2500): Loss: 0.1313\n","===> Epoch[6](600/2500): Loss: 0.1840\n","===> Epoch[6](700/2500): Loss: 0.1851\n","===> Epoch[6](800/2500): Loss: 0.1856\n","===> Epoch[6](900/2500): Loss: 0.1353\n","===> Epoch[6](1000/2500): Loss: 0.1080\n","===> Epoch[6](1100/2500): Loss: 0.0773\n","===> Epoch[6](1200/2500): Loss: 0.2904\n","===> Epoch[6](1300/2500): Loss: 0.1933\n","===> Epoch[6](1400/2500): Loss: 0.1501\n","===> Epoch[6](1500/2500): Loss: 0.2531\n","===> Epoch[6](1600/2500): Loss: 0.2557\n","===> Epoch[6](1700/2500): Loss: 0.1534\n","===> Epoch[6](1800/2500): Loss: 0.1048\n","===> Epoch[6](1900/2500): Loss: 0.2107\n","===> Epoch[6](2000/2500): Loss: 0.1343\n","===> Epoch[6](2100/2500): Loss: 0.2398\n","===> Epoch[6](2200/2500): Loss: 0.1957\n","===> Epoch[6](2300/2500): Loss: 0.2355\n","===> Epoch[6](2400/2500): Loss: 0.1432\n","===> Epoch[6](2500/2500): Loss: 0.1519\n","===> Epoch 6 Complete: Avg. Loss: 0.1749\n","===> Epoch[7](100/2500): Loss: 0.1609\n","===> Epoch[7](200/2500): Loss: 0.1491\n","===> Epoch[7](300/2500): Loss: 0.1266\n","===> Epoch[7](400/2500): Loss: 0.2358\n","===> Epoch[7](500/2500): Loss: 0.2391\n","===> Epoch[7](600/2500): Loss: 0.0857\n","===> Epoch[7](700/2500): Loss: 0.2704\n","===> Epoch[7](800/2500): Loss: 0.1666\n","===> Epoch[7](900/2500): Loss: 0.1298\n","===> Epoch[7](1000/2500): Loss: 0.1245\n","===> Epoch[7](1100/2500): Loss: 0.1464\n","===> Epoch[7](1200/2500): Loss: 0.1080\n","===> Epoch[7](1300/2500): Loss: 0.1771\n","===> Epoch[7](1400/2500): Loss: 0.1406\n","===> Epoch[7](1500/2500): Loss: 0.1312\n","===> Epoch[7](1600/2500): Loss: 0.1449\n","===> Epoch[7](1700/2500): Loss: 0.1901\n","===> Epoch[7](1800/2500): Loss: 0.2398\n","===> Epoch[7](1900/2500): Loss: 0.2262\n","===> Epoch[7](2000/2500): Loss: 0.1413\n","===> Epoch[7](2100/2500): Loss: 0.1625\n","===> Epoch[7](2200/2500): Loss: 0.1648\n","===> Epoch[7](2300/2500): Loss: 0.1610\n","===> Epoch[7](2400/2500): Loss: 0.1584\n","===> Epoch[7](2500/2500): Loss: 0.1287\n","===> Epoch 7 Complete: Avg. Loss: 0.1711\n","===> Epoch[8](100/2500): Loss: 0.2057\n","===> Epoch[8](200/2500): Loss: 0.1424\n","===> Epoch[8](300/2500): Loss: 0.1258\n","===> Epoch[8](400/2500): Loss: 0.1152\n","===> Epoch[8](500/2500): Loss: 0.1147\n","===> Epoch[8](600/2500): Loss: 0.1620\n","===> Epoch[8](700/2500): Loss: 0.1561\n","===> Epoch[8](800/2500): Loss: 0.1462\n","===> Epoch[8](900/2500): Loss: 0.1118\n","===> Epoch[8](1000/2500): Loss: 0.1125\n","===> Epoch[8](1100/2500): Loss: 0.2252\n","===> Epoch[8](1200/2500): Loss: 0.2432\n","===> Epoch[8](1300/2500): Loss: 0.1844\n","===> Epoch[8](1400/2500): Loss: 0.2013\n","===> Epoch[8](1500/2500): Loss: 0.1921\n","===> Epoch[8](1600/2500): Loss: 0.1482\n","===> Epoch[8](1700/2500): Loss: 0.1858\n","===> Epoch[8](1800/2500): Loss: 0.2211\n","===> Epoch[8](1900/2500): Loss: 0.1750\n","===> Epoch[8](2000/2500): Loss: 0.1035\n","===> Epoch[8](2100/2500): Loss: 0.2640\n","===> Epoch[8](2200/2500): Loss: 0.2112\n","===> Epoch[8](2300/2500): Loss: 0.1907\n","===> Epoch[8](2400/2500): Loss: 0.1153\n","===> Epoch[8](2500/2500): Loss: 0.1691\n","===> Epoch 8 Complete: Avg. Loss: 0.1706\n","===> Epoch[9](100/2500): Loss: 0.1669\n","===> Epoch[9](200/2500): Loss: 0.2040\n","===> Epoch[9](300/2500): Loss: 0.0922\n","===> Epoch[9](400/2500): Loss: 0.1560\n","===> Epoch[9](500/2500): Loss: 0.1201\n","===> Epoch[9](600/2500): Loss: 0.1637\n","===> Epoch[9](700/2500): Loss: 0.1810\n","===> Epoch[9](800/2500): Loss: 0.1561\n","===> Epoch[9](900/2500): Loss: 0.2150\n","===> Epoch[9](1000/2500): Loss: 0.1700\n","===> Epoch[9](1100/2500): Loss: 0.1389\n","===> Epoch[9](1200/2500): Loss: 0.0936\n","===> Epoch[9](1300/2500): Loss: 0.1022\n","===> Epoch[9](1400/2500): Loss: 0.2009\n","===> Epoch[9](1500/2500): Loss: 0.1528\n","===> Epoch[9](1600/2500): Loss: 0.0866\n","===> Epoch[9](1700/2500): Loss: 0.2311\n","===> Epoch[9](1800/2500): Loss: 0.1373\n","===> Epoch[9](1900/2500): Loss: 0.1369\n","===> Epoch[9](2000/2500): Loss: 0.2156\n","===> Epoch[9](2100/2500): Loss: 0.1081\n","===> Epoch[9](2200/2500): Loss: 0.1023\n","===> Epoch[9](2300/2500): Loss: 0.0752\n","===> Epoch[9](2400/2500): Loss: 0.1679\n","===> Epoch[9](2500/2500): Loss: 0.2789\n","===> Epoch 9 Complete: Avg. Loss: 0.1696\n","===> Epoch[10](100/2500): Loss: 0.2091\n","===> Epoch[10](200/2500): Loss: 0.1625\n","===> Epoch[10](300/2500): Loss: 0.1278\n","===> Epoch[10](400/2500): Loss: 0.1804\n","===> Epoch[10](500/2500): Loss: 0.1250\n","===> Epoch[10](600/2500): Loss: 0.0983\n","===> Epoch[10](700/2500): Loss: 0.1717\n","===> Epoch[10](800/2500): Loss: 0.1290\n","===> Epoch[10](900/2500): Loss: 0.2650\n","===> Epoch[10](1000/2500): Loss: 0.2088\n","===> Epoch[10](1100/2500): Loss: 0.3104\n","===> Epoch[10](1200/2500): Loss: 0.1806\n","===> Epoch[10](1300/2500): Loss: 0.2445\n","===> Epoch[10](1400/2500): Loss: 0.3505\n","===> Epoch[10](1500/2500): Loss: 0.2346\n","===> Epoch[10](1600/2500): Loss: 0.0881\n","===> Epoch[10](1700/2500): Loss: 0.2797\n","===> Epoch[10](1800/2500): Loss: 0.1270\n","===> Epoch[10](1900/2500): Loss: 0.1212\n","===> Epoch[10](2000/2500): Loss: 0.1293\n","===> Epoch[10](2100/2500): Loss: 0.1947\n","===> Epoch[10](2200/2500): Loss: 0.1202\n","===> Epoch[10](2300/2500): Loss: 0.1483\n","===> Epoch[10](2400/2500): Loss: 0.2718\n","===> Epoch[10](2500/2500): Loss: 0.1897\n","===> Epoch 10 Complete: Avg. Loss: 0.1705\n","Checkpoint saved to TrainedNet/_epoch_10.pth\n","===> Epoch[11](100/2500): Loss: 0.1277\n","===> Epoch[11](200/2500): Loss: 0.2818\n","===> Epoch[11](300/2500): Loss: 0.1575\n","===> Epoch[11](400/2500): Loss: 0.2036\n","===> Epoch[11](500/2500): Loss: 0.1089\n","===> Epoch[11](600/2500): Loss: 0.2101\n","===> Epoch[11](700/2500): Loss: 0.1589\n","===> Epoch[11](800/2500): Loss: 0.1052\n","===> Epoch[11](900/2500): Loss: 0.2442\n","===> Epoch[11](1000/2500): Loss: 0.1087\n","===> Epoch[11](1100/2500): Loss: 0.1901\n","===> Epoch[11](1200/2500): Loss: 0.1315\n","===> Epoch[11](1300/2500): Loss: 0.1996\n","===> Epoch[11](1400/2500): Loss: 0.2490\n","===> Epoch[11](1500/2500): Loss: 0.1429\n","===> Epoch[11](1600/2500): Loss: 0.0693\n","===> Epoch[11](1700/2500): Loss: 0.1469\n","===> Epoch[11](1800/2500): Loss: 0.1065\n","===> Epoch[11](1900/2500): Loss: 0.1210\n","===> Epoch[11](2000/2500): Loss: 0.1362\n","===> Epoch[11](2100/2500): Loss: 0.1870\n","===> Epoch[11](2200/2500): Loss: 0.1654\n","===> Epoch[11](2300/2500): Loss: 0.1342\n","===> Epoch[11](2400/2500): Loss: 0.1377\n","===> Epoch[11](2500/2500): Loss: 0.2078\n","===> Epoch 11 Complete: Avg. Loss: 0.1662\n","===> Epoch[12](100/2500): Loss: 0.0998\n","===> Epoch[12](200/2500): Loss: 0.1641\n","===> Epoch[12](300/2500): Loss: 0.1412\n","===> Epoch[12](400/2500): Loss: 0.1510\n","===> Epoch[12](500/2500): Loss: 0.1336\n","===> Epoch[12](600/2500): Loss: 0.2714\n","===> Epoch[12](700/2500): Loss: 0.1857\n","===> Epoch[12](800/2500): Loss: 0.1891\n","===> Epoch[12](900/2500): Loss: 0.2805\n","===> Epoch[12](1000/2500): Loss: 0.0988\n","===> Epoch[12](1100/2500): Loss: 0.1193\n","===> Epoch[12](1200/2500): Loss: 0.1394\n","===> Epoch[12](1300/2500): Loss: 0.1471\n","===> Epoch[12](1400/2500): Loss: 0.1388\n","===> Epoch[12](1500/2500): Loss: 0.1207\n","===> Epoch[12](1600/2500): Loss: 0.1840\n","===> Epoch[12](1700/2500): Loss: 0.1298\n","===> Epoch[12](1800/2500): Loss: 0.1485\n","===> Epoch[12](1900/2500): Loss: 0.2756\n","===> Epoch[12](2000/2500): Loss: 0.2565\n","===> Epoch[12](2100/2500): Loss: 0.0596\n","===> Epoch[12](2200/2500): Loss: 0.2140\n","===> Epoch[12](2300/2500): Loss: 0.2135\n","===> Epoch[12](2400/2500): Loss: 0.1400\n","===> Epoch[12](2500/2500): Loss: 0.2163\n","===> Epoch 12 Complete: Avg. Loss: 0.1653\n","===> Epoch[13](100/2500): Loss: 0.1425\n","===> Epoch[13](200/2500): Loss: 0.2034\n","===> Epoch[13](300/2500): Loss: 0.2398\n","===> Epoch[13](400/2500): Loss: 0.1289\n","===> Epoch[13](500/2500): Loss: 0.2694\n","===> Epoch[13](600/2500): Loss: 0.2218\n","===> Epoch[13](700/2500): Loss: 0.1952\n","===> Epoch[13](800/2500): Loss: 0.2059\n","===> Epoch[13](900/2500): Loss: 0.1910\n","===> Epoch[13](1000/2500): Loss: 0.1911\n","===> Epoch[13](1100/2500): Loss: 0.2057\n","===> Epoch[13](1200/2500): Loss: 0.2036\n","===> Epoch[13](1300/2500): Loss: 0.2276\n","===> Epoch[13](1400/2500): Loss: 0.1736\n","===> Epoch[13](1500/2500): Loss: 0.0912\n","===> Epoch[13](1600/2500): Loss: 0.1435\n","===> Epoch[13](1700/2500): Loss: 0.1949\n","===> Epoch[13](1800/2500): Loss: 0.1145\n","===> Epoch[13](1900/2500): Loss: 0.1337\n","===> Epoch[13](2000/2500): Loss: 0.1597\n","===> Epoch[13](2100/2500): Loss: 0.1840\n","===> Epoch[13](2200/2500): Loss: 0.1737\n","===> Epoch[13](2300/2500): Loss: 0.2340\n","===> Epoch[13](2400/2500): Loss: 0.1199\n","===> Epoch[13](2500/2500): Loss: 0.2225\n","===> Epoch 13 Complete: Avg. Loss: 0.1649\n","===> Epoch[14](100/2500): Loss: 0.1653\n","===> Epoch[14](200/2500): Loss: 0.1365\n","===> Epoch[14](300/2500): Loss: 0.1467\n","===> Epoch[14](400/2500): Loss: 0.1808\n","===> Epoch[14](500/2500): Loss: 0.1946\n","===> Epoch[14](600/2500): Loss: 0.1717\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/US3RN-main/main.py\", line 182, in <module>\n","    avg_loss = train(epoch, optimizer, scheduler)\n","  File \"/content/drive/MyDrive/US3RN-main/main.py\", line 107, in train\n","    W, Y, Z, X = batch[0].cuda(), batch[1].cuda(), batch[2].cuda(), batch[3].cuda()\n","KeyboardInterrupt\n"]}],"source":["!python main.py --mode train"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}